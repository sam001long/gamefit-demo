<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <title>GameFit 臉部骨架 Demo（BlazeFace）</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <!-- 只用 tfjs + blazeface，避免 Mediapipe 相容問題 -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>

  <style>
    body {
      margin: 0;
      background: #020617;
      color: #e5e7eb;
      font-family: -apple-system, BlinkMacSystemFont, sans-serif;
      text-align: center;
      padding: 12px;
    }
    h1 { font-size: 20px; margin-bottom: 6px; }
    #status { font-size: 14px; color: #38bdf8; margin-bottom: 8px; }
    #box {
      position: relative;
      width: 100%;
      max-width: 420px;
      margin: 0 auto;
      aspect-ratio: 3/4;
      background: #000;
      border-radius: 12px;
      overflow: hidden;
      border: 1px solid #1f2937;
    }
    #video, #canvas {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: contain;
    }
    #canvas { pointer-events: none; }
    #hint {
      font-size: 11px;
      color: #9ca3af;
      margin-top: 8px;
      line-height: 1.4;
    }
  </style>
</head>

<body>
  <h1>臉部骨架 Demo（BlazeFace）</h1>
  <div id="status">載入中…</div>

  <div id="box">
    <video id="video" playsinline></video>
    <canvas id="canvas"></canvas>
  </div>

  <div id="hint">
    使用方式：<br>
    1. 使用前鏡頭，將臉移到畫面中央。<br>
    2. 偵測成功時，會畫出雙眼、鼻子、嘴巴、雙耳等關鍵點。<br>
    3. 之後若要做表情辨識，我們可以再在此基礎上加上分類邏輯。<br>
  </div>

<script>
let model;
const video  = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx    = canvas.getContext("2d");
const statusEl = document.getElementById("status");

async function setupCamera() {
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "user" },
    audio: false
  });
  video.srcObject = stream;

  return new Promise(resolve => {
    video.onloadedmetadata = () => {
      video.play();
      canvas.width  = video.videoWidth;
      canvas.height = video.videoHeight;
      resolve();
    };
  });
}

function drawPredictions(predictions) {
  ctx.clearRect(0,0,canvas.width,canvas.height);

  if (!predictions || predictions.length === 0) {
    statusEl.textContent = "尚未偵測到臉部，請靠近一點或調整光線";
    return;
  }

  statusEl.textContent = "已偵測到臉部關鍵點";

  predictions.forEach(p => {
    const landmarks = p.landmarks; // [右眼, 左眼, 鼻子, 嘴巴, 右耳, 左耳]

    // 畫關鍵點
    ctx.fillStyle   = "#38bdf8";
    ctx.shadowColor = "#38bdf8";
    ctx.shadowBlur  = 10;

    landmarks.forEach(([x,y]) => {
      ctx.beginPath();
      ctx.arc(x, y, 4, 0, Math.PI * 2);
      ctx.fill();
    });

    // 略畫一個臉部外框（bounding box）
    const [x1, y1, x2, y2] = p.topLeft.concat(p.bottomRight);
    ctx.shadowBlur = 0;
    ctx.strokeStyle = "rgba(148,163,184,0.8)";
    ctx.lineWidth = 2;
    ctx.beginPath();
    ctx.roundRect(x1, y1, x2 - x1, y2 - y1, 8);
    ctx.stroke();
  });
}

async function loop() {
  const predictions = await model.estimateFaces(video, false);
  drawPredictions(predictions);
  requestAnimationFrame(loop);
}

async function main() {
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    alert("此瀏覽器不支援相機，請改用 iPhone Safari 或新版 Chrome。");
    return;
  }

  await setupCamera();
  await tf.ready();

  model = await blazeface.load();
  statusEl.textContent = "模型載入完成，請將臉移到畫面中間";

  loop();
}

main().catch(err => {
  console.error(err);
  alert("初始化失敗：" + err.message);
});
</script>
</body>
</html>
